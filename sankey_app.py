import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from google.oauth2 import service_account
from google.cloud import bigquery
import base64
import re

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")
st.title("\U0001F9ED Sankey Diagram")

# UIì—ì„œ ì¹´í…Œê³ ë¦¬ ì…ë ¥ ë°›ê¸°
category_input = st.text_input('ì¹´í…Œê³ ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:', '')
category_select = st.selectbox('ì¹´í…Œê³ ë¦¬ ì„ íƒ', ['ìŠ¤íƒ ë°”ì´ë¯¸', 'ëƒ‰ì¥ê³ ', 'ì„¸íƒê¸°', 'TV'])
selected_category = category_input if category_input else category_select
st.markdown(f"### \U0001F50D ì„ íƒëœ ì¹´í…Œê³ ë¦¬: `{selected_category}`")

# ì¸ì¦ ì²˜ë¦¬
secrets = st.secrets["gcp_service_account"]
private_key = base64.b64decode(secrets["private_key"]).decode()
credentials = service_account.Credentials.from_service_account_info({
    "type": secrets["type"],
    "project_id": secrets["project_id"],
    "private_key_id": secrets["private_key_id"],
    "private_key": private_key,
    "client_email": secrets["client_email"],
    "client_id": secrets["client_id"],
    "auth_uri": secrets["auth_uri"],
    "token_uri": secrets["token_uri"],
    "auth_provider_x509_cert_url": secrets["auth_provider_x509_cert_url"],
    "client_x509_cert_url": secrets["client_x509_cert_url"]
})
client = bigquery.Client(credentials=credentials, project=secrets["project_id"])

# ë°ì´í„° ì¿¼ë¦¬
query = """
    SELECT user_session_id, step, page
    FROM `lge-big-query-data.hsad.test_0423_2`
    WHERE category = @category
    ORDER BY user_session_id, step
"""
job_config = bigquery.QueryJobConfig(
    query_parameters=[bigquery.ScalarQueryParameter("category", "STRING", selected_category)]
)
df = client.query(query, job_config=job_config).to_dataframe()
df = df.dropna(subset=['user_session_id', 'step', 'page'])
df['page'] = df['page'].astype(str).str.strip().str.replace(r'\s+', '', regex=True)

# âœ… ì„¸ì…˜ ì‹œì‘ ë…¸ë“œ ì¡°ê±´
sessions_with_step1 = df[df['step'] == 1]['user_session_id'].unique()
df = df[df['user_session_id'].isin(sessions_with_step1)]


df = df.sort_values(['user_session_id', 'step']) 
df['step'] = df.groupby('user_session_id').cumcount() + 1

last_pages = df.groupby('user_session_id').tail(1)
st.write(last_pages['page'].value_counts())

# âœ… ì„¸ì…˜ë³„ page ë¦¬ìŠ¤íŠ¸ë¡œ ê²½ë¡œ ìƒì„±
session_paths = df.groupby('user_session_id')['page'].apply(list).reset_index()
session_paths['path_str'] = session_paths['page'].apply(lambda x: ' > '.join(x))
path_counts = session_paths['path_str'].value_counts().reset_index()
path_counts.columns = ['path', 'value']

# âœ… pair ìƒì„±
def path_to_pairs(path_str, value):
    steps = path_str.split(' > ')
    pairs = []
    for i in range(len(steps) - 1):
        source = f"{steps[i]} ({i+1}ë‹¨ê³„)" if i > 0 else "ì„¸ì…˜ ì‹œì‘"
        target = f"{steps[i+1]} ({i+2}ë‹¨ê³„)"
        pairs.append((source, target, value))
    return pairs

pairs = []
for _, row in path_counts.iterrows():
    pairs.extend(path_to_pairs(row['path'], row['value']))

pairs_df = pd.DataFrame(pairs, columns=['source', 'target', 'value'])
pairs_agg = pairs_df.groupby(['source', 'target'])['value'].sum().reset_index()

# âœ… value â‰¥ 5 ê¸°ì¤€ BFS í•„í„°ë§


# --- -----------------------------------------------------------------------------------------------------------------------------------------------
# --- í•¨ìˆ˜ ì •ì˜ ---
def get_base_node_name(label):
    return re.sub(r'\s*\(\d+ë‹¨ê³„\)', '', label)  # ë‹¨ê³„ ì œê±°

def is_terminal_exception(node):
    if not isinstance(node, str):
        return False
    base = get_base_node_name(node)
    return base in ['ì£¼ë¬¸ì™„ë£Œ', 'ì²­ì•½ì™„ë£Œ']

# --- 0. í˜ì´ì§€ í´ë Œì§• ---
df['page'] = df['page'].astype(str).str.strip().str.replace(r'\s+', '', regex=True)

# --- 1. ì„¸ì…˜ ì¢…ë£Œê°€ ì£¼ë¬¸ì™„ë£Œ ë˜ëŠ” ì²­ì•½ì™„ë£Œì¸ ê²½ìš°ë§Œ ìœ ì§€ ---
last_pages = df.groupby('user_session_id').tail(1)
valid_sessions = last_pages[last_pages['page'].isin(['ì£¼ë¬¸ì™„ë£Œ', 'ì²­ì•½ì™„ë£Œ'])]['user_session_id'].unique()
df = df[df['user_session_id'].isin(valid_sessions)].copy()

# --- 1.5 step ì¬ê³„ì‚°ì„ ìœ„í•´ ì„¸ì…˜ ë‚´ë¶€ ìˆœì„œë¥¼ ë³´ì¥í•˜ëŠ” ì¸ë±ìŠ¤ë¥¼ ìƒì„± (ê°•ì œ ìˆœì„œìš©)
df = df.reset_index(drop=True)
df['seq'] = df.groupby('user_session_id').cumcount()  # ê°•ì œë¡œ ìˆœì„œ ë¶€ì—¬

# --- 2. step ì¬ê³„ì‚° ë° ê²½ë¡œ ìƒì„± ---
df = df.sort_values(['user_session_id', 'seq'])  # seq ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬

# ìƒˆë¡­ê²Œ step ë¶€ì—¬
df['step'] = df.groupby('user_session_id').cumcount() + 1

session_paths = df.groupby('user_session_id')['page'].apply(list).reset_index()
session_paths['path_str'] = session_paths['page'].apply(lambda x: ' > '.join(x))
path_counts = session_paths['path_str'].value_counts().reset_index()
path_counts.columns = ['path', 'value']

# --- 3. pair ìƒì„± ---

def path_to_pairs(path_str, value):
    steps = path_str.split(' > ')
    pairs = []
    for i in range(len(steps) - 1):
        source = f"{steps[i]} ({i+1}ë‹¨ê³„)" if i > 0 else "ì„¸ì…˜ ì‹œì‘"
        target = f"{steps[i+1]} ({i+2}ë‹¨ê³„)"
        pairs.append((source, target, value))
    return pairs

pairs = []
for _, row in path_counts.iterrows():
    pairs.extend(path_to_pairs(row['path'], row['value']))

import pandas as pd
pairs_df = pd.DataFrame(pairs, columns=['source', 'target', 'value'])

# --- 3.5 ë¶ˆí•„ìš”í•œ ë…¸ë“œ ì‚¬ì „ ì œê±° ---
def is_excluded_node(label):
    base = get_base_node_name(label)
    return base in ['ê¸°íšì „ìƒì„¸', 'ë§ˆì´í˜ì´ì§€']

pairs_df = pairs_df[
    ~pairs_df['source'].apply(is_excluded_node) &
    ~pairs_df['target'].apply(is_excluded_node)
].reset_index(drop=True)

# --- 3.6 ì„¸ì…˜ ì‹œì‘ì—ì„œ ë¶ˆí•„ìš”í•œ ë…¸ë“œë¡œ ë°”ë¡œ ê°€ëŠ” ê²½ìš° ì œê±° ---
pairs_df = pairs_df[
    ~((pairs_df['source'] == 'ì„¸ì…˜ ì‹œì‘') & (pairs_df['target'].apply(is_excluded_node)))
].reset_index(drop=True)

pairs_agg = pairs_df.groupby(['source', 'target'])['value'].sum().reset_index()

# --- 4. ì¢…ë£Œ ë…¸ë“œ: ì‹¤ì œ df ê¸°ì¤€ ì¢…ë£Œ ë…¸ë“œ êµ¬í•¨ ---
# (ë¶ˆí•„ìš”í•œ terminal_nodes_with_step ì œê±°ë¨)

# --- 5. BFS í•„í„°ë§ with ì˜ˆì™¸ í—ˆìš© ---

def is_valid_start(target_label):
    return True  # âœ… ëª¨ë“  ì‹œì‘ ë…¸ë“œë¥¼ í—ˆìš©í•˜ë„ë¡ ë³€ê²½

seed_edges = pairs_agg[
    (pairs_agg['source'] == 'ì„¸ì…˜ ì‹œì‘') &
    (pairs_agg['target'].apply(is_valid_start))
]

valid_nodes = set(seed_edges['target']) | {'ì„¸ì…˜ ì‹œì‘'}
visited_edges = set()
exception_pages = ['ì£¼ë¬¸ì™„ë£Œ', 'ì²­ì•½ì™„ë£Œ']  # âœ… page ê¸°ì¤€ ì˜ˆì™¸ ì²˜ë¦¬

def is_exception_edge(row):
    return (
        get_base_node_name(row['source']) in exception_pages or
        get_base_node_name(row['target']) in exception_pages
    )

expanded = True
while expanded:
    current_size = len(valid_nodes)

    valid_edges = pairs_agg[
        (pairs_agg['source'].isin(valid_nodes)) &
        (
            (pairs_agg['value'] >= 10) |
            pairs_agg.apply(is_exception_edge, axis=1)
        )
    ]

    for _, row in valid_edges.iterrows():
        visited_edges.add((row['source'], row['target']))
        valid_nodes.add(row['target'])

    expanded = len(valid_nodes) > current_size

# --- 6. ìµœì¢… í•„í„°ë§ ì ìš© ---
pairs_agg = pairs_agg[
    pairs_agg.apply(lambda row: (row['source'], row['target']) in visited_edges, axis=1)
]


# --- -------------------------------------------------------------------------------------------------------------------------------------------




# âœ… ë…¸ë“œ ë§¤í•‘ ë° ì¢Œí‘œ ê³„ì‚°
all_nodes = pd.unique(pairs_agg[['source', 'target']].values.ravel())
node_map = {name: i for i, name in enumerate(all_nodes)}
pairs_agg['source_id'] = pairs_agg['source'].map(node_map)
pairs_agg['target_id'] = pairs_agg['target'].map(node_map)

def extract_step(label):
    if label == "ì„¸ì…˜ ì‹œì‘": return 0
    match = re.search(r"\((\d+)ë‹¨ê³„\)", label)
    return int(match.group(1)) if match else 0

valid_nodes_set = set(pairs_agg['source']).union(set(pairs_agg['target']))
depth_map = {node: extract_step(node) for node in valid_nodes_set}
max_depth = max(depth_map.values()) if depth_map else 1
node_x = [depth_map.get(name, 0) / max_depth for name in node_map.keys()]

# âœ… Sankey ì‹œê°í™”
fig = go.Figure(data=[go.Sankey(
    arrangement="fixed",
    node=dict(
        pad=20,  # ë…¸ë“œ ê°„ ì—¬ë°± í™•ëŒ€
        thickness=30,  # ë…¸ë“œ ë‘ê»˜ í™•ëŒ€
        label=list(node_map.keys()),
        line=dict(color="black", width=0.5),
        x=node_x
    ),
    link=dict(
        source=pairs_agg['source_id'],
        target=pairs_agg['target_id'],
        value=pairs_agg['value']
    )
)])

fig.update_layout(
    title_text=f"ì„¸ì…˜ ê¸°ë°˜ Sankey for `{selected_category}`",
    font=dict(size=14),  # ğŸ” í…ìŠ¤íŠ¸ í¬ê¸° í™•ëŒ€
    width=1200,          # ğŸ” ì°¨íŠ¸ ê°€ë¡œ í¬ê¸° í™•ëŒ€
    height=700,          # ğŸ” ì°¨íŠ¸ ì„¸ë¡œ í¬ê¸° í™•ëŒ€
    margin=dict(l=20, r=20, t=60, b=20)  # ì—¬ë°± ì¡°ì •
)

st.plotly_chart(fig, use_container_width=False)

