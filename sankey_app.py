import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from google.oauth2 import service_account
from google.cloud import bigquery
import base64

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(layout="wide")
st.title("ğŸ§­ Sankey Diagram")

# UIì—ì„œ ì¹´í…Œê³ ë¦¬ ì…ë ¥ ë°›ê¸°
category_input = st.text_input('ì¹´í…Œê³ ë¦¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:', '')  # í…ìŠ¤íŠ¸ ì…ë ¥ë€
category_select = st.selectbox('ì¹´í…Œê³ ë¦¬ ì„ íƒ', ['ìŠ¤íƒ ë°”ì´ë¯¸', 'ëƒ‰ì¥ê³ ', 'ì„¸íƒê¸°', 'TV'])  # ì…€ë ‰íŠ¸ë°•ìŠ¤

# ìµœì¢… ì¹´í…Œê³ ë¦¬ ê²°ì •
if category_input:
    selected_category = category_input  # í…ìŠ¤íŠ¸ ì…ë ¥ ê°’ì´ ìˆìœ¼ë©´ ì…ë ¥ ê°’ ì‚¬ìš©
else:
    selected_category = category_select  # í…ìŠ¤íŠ¸ ì…ë ¥ ê°’ì´ ì—†ìœ¼ë©´ ì…€ë ‰íŠ¸ë°•ìŠ¤ ê°’ ì‚¬ìš©
    
st.markdown(f"### ğŸ” ì„ íƒëœ ì¹´í…Œê³ ë¦¬: `{selected_category}`")


# ğŸŒ Streamlit secretsì—ì„œ ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
secrets = st.secrets["gcp_service_account"]

# base64ë¡œ ì¸ì½”ë”©ëœ private_keyë¥¼ ë³µì›
private_key = base64.b64decode(secrets["private_key"]).decode()

# âœ… Credentials ìƒì„±
credentials = service_account.Credentials.from_service_account_info({
    "type": secrets["type"],
    "project_id": secrets["project_id"],
    "private_key_id": secrets["private_key_id"],
    "private_key": private_key,  # ì´ì œ private_keyë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    "client_email": secrets["client_email"],
    "client_id": secrets["client_id"],
    "auth_uri": secrets["auth_uri"],
    "token_uri": secrets["token_uri"],
    "auth_provider_x509_cert_url": secrets["auth_provider_x509_cert_url"],
    "client_x509_cert_url": secrets["client_x509_cert_url"]
})

# ğŸš€ BigQuery ì—°ê²°
client = bigquery.Client(credentials=credentials, project=secrets["project_id"])

# ì¿¼ë¦¬ ì‹¤í–‰
query = """
       SELECT user_session_id, step, page
    FROM `lge-big-query-data.hsad.test_0423_2`
    WHERE category = @category
    ORDER BY user_session_id, step
"""
job_config = bigquery.QueryJobConfig(
    query_parameters=[bigquery.ScalarQueryParameter("category", "STRING", selected_category)]
)

df = client.query(query, job_config=job_config).to_dataframe()
df = df.dropna(subset=['user_session_id', 'step', 'page']) # âœ… ì•ˆì •í™”: í•„ìˆ˜ ì»¬ëŸ¼ì— null ìˆìœ¼ë©´ ì œê±°

# step=1ì´ ì¡´ì¬í•˜ëŠ” ì„¸ì…˜ë§Œ ë‚¨ê¸´ë‹¤ (ì„¸ì…˜ ì‹œì‘ ë…¸ë“œ êµ¬ì„± ê°€ëŠ¥í•˜ë„ë¡)
sessions_with_step1 = df[df['step'] == 1]['user_session_id'].unique()
df = df[df['user_session_id'].isin(sessions_with_step1)]

# ì£¼ë¬¸ì™„ë£Œ í¬í•¨ ì„¸ì…˜ë§Œ ìœ ì§€ (ì´ê±¸ ìë¥´ê¸° ì „ì— ë¨¼ì € ì ìš©í•´ì•¼ í•¨!)
sessions_with_purchase = df[df['page'] == 'ì£¼ë¬¸ì™„ë£Œ']['user_session_id'].unique()
df = df[df['user_session_id'].isin(sessions_with_purchase)]

# êµ¬ë§¤ì™„ë£Œ ì´í›„ ë‹¨ê³„ëŠ” ì œê±°í•˜ëŠ” í•¨ìˆ˜
def truncate_after_purchase(df):
    trimmed_rows = []
    for session_id, group in df.groupby('user_session_id'):
        group_sorted = group.sort_values('step')
        for row in group_sorted.itertuples():
            trimmed_rows.append(row)
            if row.page == 'ì£¼ë¬¸ì™„ë£Œ':  # êµ¬ë§¤ì™„ë£Œ ì‹œ ì¤‘ë‹¨
                break
    return pd.DataFrame(trimmed_rows).drop_duplicates()

# dfì— ì ìš©
df = truncate_after_purchase(df)


# ë§ˆì§€ë§‰ stepì´ 'ì£¼ë¬¸ì™„ë£Œ'ì¸ ì„¸ì…˜ë§Œ ìœ ì§€
last_steps = df.sort_values(['user_session_id', 'step']).groupby('user_session_id').tail(1)
valid_sessions = last_steps[last_steps['page'] == 'ì£¼ë¬¸ì™„ë£Œ']['user_session_id'].unique()
df = df[df['user_session_id'].isin(valid_sessions)]
df['step'] = df.groupby('user_session_id').cumcount() + 1 # ë‹¤ì‹œ step ì¬ì •ì˜: truncate í›„ stepì´ ì—°ì†ë˜ë„ë¡ ë³´ì¥

# ğŸ› ï¸ ì„¸ì…˜ë³„ íë¦„ ì—°ê²°
pairs = []

for session_id, group in df.groupby('user_session_id'):
    sorted_rows = group.sort_values('step')[['page', 'step']]
    pages = [f"{row.page} ({row.step}ë‹¨ê³„)" for row in sorted_rows.itertuples()]
    
    if pages:
        pairs.append(("ì„¸ì…˜ ì‹œì‘", pages[0]))  # ì‹œì‘ ë…¸ë“œ ì¶”ê°€
    
    for i in range(len(pages) - 1):
        pairs.append((pages[i], pages[i + 1]))

        
# âœ… ë¹ˆë„ìˆ˜ ì§‘ê³„        
pairs_df = pd.DataFrame(pairs, columns=['source', 'target'])
pairs_agg = pairs_df.value_counts().reset_index(name='value')


# âœ… 'ì„¸ì…˜ ì‹œì‘' ì¤‘ value â‰¥ 5ì¸ ê²ƒë§Œ seedë¡œ ì‚¬ìš©
seed_nodes = pairs_agg[
    (pairs_agg['source'] == 'ì„¸ì…˜ ì‹œì‘') & (pairs_agg['value'] >= 5)
]['target'].unique()


# âœ… BFS í™•ì¥ (ìœ íš¨í•œ íë¦„ë§Œ ë”°ë¼ê°€ë©° í™•ì¥)
valid_nodes = set(seed_targets) | {'ì„¸ì…˜ ì‹œì‘'}
visited_edges = set()
expanded = True

while expanded:
    current_size = len(valid_nodes)
    # value â‰¥ 5ì¸ edgeë§Œ ë”°ë¼ê°€ê¸°
    valid_edges = pairs_agg[
        (pairs_agg['source'].isin(valid_nodes)) &
        (pairs_agg['value'] >= 5)
    ]

    for _, row in valid_edges.iterrows():
        visited_edges.add((row['source'], row['target']))
        valid_nodes.add(row['target'])

    expanded = len(valid_nodes) > current_size


# âœ… ìµœì¢… í•„í„°ë§ ì ìš©
pairs_agg = pairs_agg[
    pairs_agg['source'].isin(valid_nodes) &
    pairs_agg['target'].isin(valid_nodes)
]

# 1. âœ… ë…¸ë“œ ë§¤í•‘
all_nodes = pd.unique(pairs_agg[['source', 'target']].values.ravel())
node_map = {name: i for i, name in enumerate(all_nodes)}

# 2. âœ… source/target ì¸ë±ìŠ¤ ë§¤í•‘
pairs_agg['source_id'] = pairs_agg['source'].map(node_map)
pairs_agg['target_id'] = pairs_agg['target'].map(node_map)

# 3. âœ… node.x ìˆ˜ë™ ì§€ì • (ë‹¨ê³„ë³„ë¡œ ì¢Œí‘œ ê³„ì‚°)
# ë‹¨ê³„ ìˆ«ì ì¶”ì¶œ (ì •ê·œì‹ ê¸°ë°˜)
import re
def extract_step(label):
    if label == "ì„¸ì…˜ ì‹œì‘":
        return 0
    match = re.search(r"\((\d+)ë‹¨ê³„\)", label)
    return int(match.group(1)) if match else 0

# ğŸ”§ ì‹¤ì œ depth_map
depth_map = {}
for session_id, group in df.groupby('user_session_id'):
    sorted_pages = group.sort_values('step')
    pages = [f"{row.page} ({row.step}ë‹¨ê³„)" for row in sorted_pages.itertuples()]
    if pages:
        depth_map["ì„¸ì…˜ ì‹œì‘"] = 0
    for idx, page in enumerate(pages):
        if page not in depth_map or depth_map[page] < idx + 1:
            depth_map[page] = idx + 1  # 1ë‹¨ê³„ë¶€í„° ì‹œì‘ (ì„¸ì…˜ ì‹œì‘ì€ 0)

# ì •ê·œí™”
max_depth = max(depth_map.values()) if depth_map else 1
node_x = [depth_map.get(name, 0) / max_depth for name in node_map.keys()]



# ğŸ¯ Sankey ê·¸ë¦¬ê¸°
fig = go.Figure(data=[go.Sankey(
    arrangement="fixed",  # x ì¢Œí‘œ ê°•ì œ ì ìš©
    node=dict(
        pad=15,
        thickness=20,
        label=list(node_map.keys()),
        line=dict(color="black", width=0.5),
        x=node_x
    ),
    link=dict(
        source=pairs_agg['source_id'],
        target=pairs_agg['target_id'],
        value=pairs_agg['value']
    )
)])

fig.update_layout(
    title_text=f"ì„¸ì…˜ ê¸°ë°˜ Sankey for `{selected_category}`",
    font_size=10,
    margin=dict(l=0, r=0, t=40, b=0)
)

# Streamlitì— ê·¸ë˜í”„ ì¶œë ¥
st.plotly_chart(fig, use_container_width=True)
